{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New Structure project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nxf-emma/APS360-Artificial-Intelligence-Fundamentals/blob/main/New_Structure_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount googledrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9YmzNJngAsK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3c9ab8-b656-4564-be16-ed43e0f29570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihbRrhOPrlrl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "img_size = 48 "
      ],
      "metadata": {
        "id": "CW1MxNmaBNS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convolutional Neural Network Architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2) #kernel_size, stride \n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 5, 3, padding = 2) #in_channels, out_chanels, kernel_size\n",
        "        self.conv2 = nn.Conv2d(5, 25, 3) #in_channels, out_chanels, kernel_size\n",
        "        self.conv3 = nn.Conv2d(25, 50, 3)\n",
        "        self.conv4 = nn.Conv2d(50, 100, 3)\n",
        "        self.conv5 = nn.Conv2d(100, 125, 3)\n",
        "        \n",
        "        self.fc1 = nn.Linear(10*1*1, 32) #chanels*dimension\n",
        "        self.fc2 = nn.Linear(32, 7) #last output channel always = 7\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        # 50x50\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        # 24x24\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        # 11x11\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        # 4x4\n",
        "        x = self.pool(F.relu(self.conv5(x)))\n",
        "        # 1x1\n",
        "\n",
        "        x = x.view(-1, 10*1*1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = x.squeeze(1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "U4pkyLBiApwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(model, dataloader):\n",
        "    \n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in dataloader:\n",
        "        \n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            imgs = imgs.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        output = model(imgs)\n",
        "        \n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "CX0EUse3A1nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, val_data, batch_size=2000, num_epochs=10, lr = 0.01):\n",
        "    \n",
        "    num_workers = 1\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "                                           num_workers=num_workers, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, shuffle=True)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    iters, losses, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "    # training\n",
        "    n = 0 # the number of iterations\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"Epoch\", epoch)\n",
        "        n = 0\n",
        "        for imgs, labels in iter(train_loader):\n",
        "            print(\"iteration \", n)\n",
        "\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                imgs = imgs.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            out = model(imgs)             # forward pass\n",
        "\n",
        "            loss = criterion(out, labels) # compute the total loss\n",
        "            loss.backward()               # backward pass (compute parameter updates)\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "            n += 1\n",
        "\n",
        "        # save the current training information\n",
        "    iters.append(epoch)\n",
        "    losses.append(float(loss)/batch_size)             # compute *average* loss\n",
        "    # calculate accuracy at each epoch instead of iteration\n",
        "    # def get_accuracy(model, data):\n",
        "    train_acc.append(get_accuracy(model, train_loader)) # compute training accuracy \n",
        "    # compute validation acc every epoch\n",
        "    val_acc.append(get_accuracy(model, val_loader))  # compute validation accuracy\n",
        "    print(\"Epoch: \", epoch, \" Validation Accuracy: \", val_acc[epoch])\n",
        "\n",
        "            \n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, train_acc, label=\"Train\")\n",
        "    plt.plot(iters, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"
      ],
      "metadata": {
        "id": "PWPxMA3gA2Gi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/APS360 Team/aps360_dataset/FER-2013_Tensors/train'\n",
        "val_path = '/content/drive/MyDrive/APS360 Team/aps360_dataset/FER-2013_Tensors/val'\n",
        "test_path = '/content/drive/MyDrive/APS360 Team/aps360_dataset/FER-2013_Tensors/test'\n",
        "\n",
        "train_data = datasets.DatasetFolder(train_path, loader=torch.load, extensions=('.tensor'))\n",
        "val_data = datasets.DatasetFolder(val_path, loader=torch.load, extensions=('.tensor'))\n",
        "test_data = datasets.DatasetFolder(test_path, loader=torch.load, extensions=('.tensor'))"
      ],
      "metadata": {
        "id": "8TP_4QGdEdVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "model = CNN()\n",
        "use_cuda = True\n",
        "model.cuda()\n"
      ],
      "metadata": {
        "id": "uQ_udpVWA72X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}